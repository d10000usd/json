[
    {
        "title": "초거대 AI 모델 연구 주제 성능 지상주의에서 효율화자동화로 옮겨간다. ",
        "newstext": "이처럼 글로벌 빅테크 기업 간 경쟁이 치열한 초거대 인공지능(ai) 모델 개발 분야에서 연산 기술 관련 연구의 무게 중심이 이동할 것이란 관측이 나왔다. 2020년 이전까지 주된 연구 주제가 모델 개발에 필요한 연산 인프라에서 막대한 성능 총량을 달성하는 것이었다면, 최근 추세를 볼 때 주어진 하드웨어 자원으로 병렬 처리 시 더 나은 성능을 얻기 위한 효율성과 운영·관리 자동화 방안이 더 주목받을 것이라는 전망이다.18일 국내 연구계에 따르면 한국전자통신연구원(etri) 연구자들은 정보통신기획평가원(iitp)의 주간기술동향 보고서에 거대 모델 병렬 학습을 위한 고효율 ai 컴퓨팅 기술 동향 연구 논문을 게재했다. 이 논문은 국가 ict 연구개발(r&d) 기획·평가·관리 업무를 전담하는 과학기술정보통신부 산하기관인 iitp의 지원으로 수행한 연구성과를 정리한 것으로, 정부 기관의 공식 의견이 아닌 연구자의 주관적인 견해를 담고 있다. etri 연구자들은 이 논문에서 대규모 모델 학습(훈련)용 하드웨어 기술 동향과 모델 연산을 처리하는 병렬화 기술 등장 흐름을 짚고 병렬화의 고난도 과제를 해결하기 위한 자동 병렬화 기술이 나오고 있다는 점에 주목했다.etri 연구자들은 현재 ai 모델은 1조개 이상 파라미터를 포함할 정도로 초거대 규모로 대형화하고 있지만 하드웨어 성능 발전 속도는 모델 규모의 성장 속도보다 턱없이 느린 상황으로 그 격차 또한 지속해서 증가한다고 봤다. 이는 데이터 내 관계를 추적해 그 맥락과 의미를 학습하는 트랜스포머 신경망 기반 모델이 단순한 구조와 규모와 비례한 성능을 보장하는 특성 때문에 2017년 처음 등장한 이래 ai 모델 대형화 추세를 가속한 결과다. 딥러닝 기법에 필요한 연산량이 18개월마다 10배, 메모리 사용량이 2년마다 35배씩 늘고 있다. 학습 단계에 필요한 연산 성능과 메모리 사용량이 단일 장치 범위를 한참 벗어났고 이는 필연적으로 다수 연산장치를 이용해 병렬로 학습하는 기술 발전으로 이어졌다고 연구자들은 지적했다.또 연구자들은 과거 두 번의 겨울을 거친 인공지능 기술은 딥러닝 기술의 등장과 하드웨어 성능의 비약적인 발전에 힘입어 그 꽃을 피우게 됐고, 현재도 인류의 예상을 뛰어넘는 수준의 속도로 발전하고 있다며 지금은 ai 기술 발전의 일등 공신이었던 하드웨어 성능이 ai 모델의 급격한 대형화 추세를 따라잡지 못해 걸림돌이 되어버린 상황으로, 이를 해결하기 위한 ai 학습 병렬화 기술이 등장해 주목을 받고 있다고 설명했다.우선 모델 규모가 급격히 커지면서 다수 서버를 연결한 클러스터 형태의 ai 하드웨어 플랫폼이 도입됐다. gpu 제조사 엔비디아는 고속 통신용 상호연결 기술 nv링크와 4세대 텐서 코어, 트랜스포머 알고리즘 처리 효율을 높이는 트랜스포머 엔진을 탑재한 gpu 제품 h100과 이를 탑재한 x86 서버를 여러 대 연결한 dgx 제품군으로 초거대 ai 모델 학습을 지원한다. 구글은 ai 연산 가속 프로세서 텐서처리장치(tpu)를 업그레이드해 2021년부터 제공하는 tpu v4 칩을 3d torus 토폴로지로 4096개 상호연결한 tpu v4 포드(pod) 하나로 최대 연산 성능 1.1엑사플롭스(bf16 또는 int8 기준)를 구현했다. 그래프코어는 딥러닝 ai 연산 가속 프로세서 지능처리장치(ipu)를 제작해 왔고 2022년 발표한 3세대 제품 bow 칩을 4개 포함한 1u 규격 서버 bow-2000 한 대로 1.4페타플롭스 성능을 내며 이를 여러 대 연결한 시스템을 구축해 성능을 확장할 수 있다.이후 서버 간 통신 부하를 최소화하면서 모델을 병렬 학습하는 효율화 기술이 주목받고 있다. 앞서 ai 모델 연산을 처리하는 각 장치에 동일 모델 사본을 두고 입력 데이터를 나눠 모델 학습을 병렬 수행하는 데이터 병렬화 기법이 도입됐고 그중 입력 데이터를 병렬 처리 후 연산장치 간 상호통신해 모델을 동기화하는 링-올리듀스(ring-allreduce) 기법을 텐서플로 프레임워크에 구현한 horovod 라이브러리가 사실상 표준으로 쓰인다. 이후 장치 내부 메모리보다 큰 ai 모델을 학습하지 못하는 데이터 병렬화 기법 한계를 극복하기 위해 파이프라인 병렬화 기법이 등장했는데, 이는 모델 각 계층을 여러 장치에 분할 저장하고 입력 데이터도 분할해 동시에 연산을 수행하는 기법이다. 이때 유휴 자원을 줄이기 위해 1f1b 외에 weight stashing, ooo backprop 등 여러 스케줄링 전략으로 파이프라인 병렬화 모델 학습 효율성을 높일 수 있다.대형 ai 모델 학습을 위해 모델 병렬화 작업을 지원하는 프레임워크도 나왔다. ai 모델 계층 자체를 여러 장치에 분할 저장 학습하는 텐서 병렬화 기법이 제안됐고, 인공신경망의 은닉계층을 대상으로 텐서 병렬화를 적용한 메시-텐서플로가 이를 최초로 딥러닝 모델에 적용한 사례였다. 초거대 ai 모델 흐름을 이끈 트랜스포머 알고리즘 기반 모델에 텐서 병렬화를 구현한 사례로 엔비디아의 메가트론(megatron)-lm이 꼽히는데, 새로 학습하기 위해 모델을 직접 수정해야 하는 노력이 많이 드는 단점이 있다. 파이토치용 프레임워크인 마이크로소프트의 바루나(varuna)는 파이토치용 프레임워크로 사용자가 학습 모델에 파이프라인 병렬화 지점을 알려주면 특정한 지점만 활성화해 모델 계층을 나누는데, 범용 하드웨어 환경에 텐서 병렬화보다 저렴한 네트워크 비용으로 파이프라인 병렬화를 구현할 수 있지만 사용자가 모델 코드를 수정해야 하는 부담이 남았다.기존 프레임워크는 동일 계층이 반복되는 모델에만 병렬화를 지원했고 조건문이 포함된 모델 병렬화가 불가능했다. 아마존 세이지메이커(amazon sagemaker)는 지원 모델 형상에 대한 유연성을 높이고 모델의 분할 영역 간 통신 횟수를 줄인 최적화 알고리즘을 적용해 모델 병렬화 기능을 일반화했다. 마이크로소프트 딥스피드(deepspeed)는 gpu뿐 아니라 cpu와 nvme 자원을 함께 사용해 기존 데이터 병렬화 기법 대비 메모리 소비량을 극적으로 절감한 최적화 기능으로 수조 개 파라미터 규모 학습을 가능하게 만들었다. 국산 프레임워크 오슬로(oslo)는 허깅 페이스 모델에 텐서 병렬화와 파이프라인 병렬화를 쉽게 지원하는 기술로 꼽혔다.etri 연구자들은 사용자가 직접 (모델) 병렬화를 하기 위해서는 높은 확률로 모델에 대한 도메인 지식을 갖춰야 한다면서 기존 모델을 자동으로 병렬화하는 기법에 관한 연구가 주목받고 있다고 했다. 한 사례로 모델 개발자가 전체 모델의 핵심 텐서에 대한 코드 몇 줄을 추가해 자동 병렬화를 수행할 수 있는 구글의 gspmd가 있다. 이는 모델 개발자에게 데이터, 파이프라인, 텐서 병렬화 기능을 모두 제공해 개발자가 대규모 연산 성능과 메모리를 갖춘 단일 가속 장치만 있다고 가정하고 ai 모델을 만들 수 있게 한다. uc버클리 연구진이 개발한 알파(alpa)는 주어진 하드웨어 성능에 맞게 대규모 ai 모델을 자동 병렬화하는 기술이다. 이를 구현한 jax 라이브러리와 xla 컴파일러가 오픈소스로 공개돼 있다. 논문에선 알파가 널리 쓰이는 주요 ai 모델에 기존 대비 우월한 성능을 검증했고 하드웨어 증설에 따른 확장성도 확인했다고 평했다.etri 연구자들은 ai 기술 역시 다른 기존 기술들과 유사하게 기능 개선→절대 성능 개선→효율 개선→자동화의 진화 사이클을 보여주고 있다며 지금까지 ai 연구 주제가 기능과 절대 성능에 초점이 맞춰졌다면 지금부터는 연구의 중심이 효율 개선과 자동화 관련 기술 쪽으로 옮겨갈 것으로 예상한다고 했다. 또 거대 규모 ai 모델의 효율적인 병렬 학습을 사람의 수작업에 의존하지 않고 자동화하는 기술의 발전은, ai 기술이 인류의 삶 속에 더욱 깊이 확산하고 보편화돼 고수준의 신기술 체험을 가능하게 하는 근간이 될 것이라고 기대했다.",
        "summary": "   이처럼 글로벌 빅테크 기업 간 경쟁이 치열한 초거대 인공지능(AI) 모델 개발 분야에서 연산 기술 관련 연구의 무게 중심이 이동할 것이란 관측이 나왔다.구글은 AI 연산 가속 프로세서 텐서처리장치(TPU)를 업그레이드해 2021년부터 제공하는 TPU v4 칩을 3D Torus 토폴로지로 4096개 상호연결한 TPU v4 포드(Pod) 하나로 최대 연산 성능 1.1엑사플롭스(bf16 또는 int8 기준)를 구현했다.이때 유휴 자원을 줄이기 위해 1F1B 외에 weight stashing, OOO backprop 등 여러 스케줄링 전략으로 파이프라인 병렬화 모델 학습 효율성을 높일 수 있다.대형 AI 모델 학습을 위해 모델 병렬화 작업을 지원하는 프레임워크도 나왔다.AI 모델 계층 자체를 여러 장치에 분할 저장 학습하는 텐서 병렬화 기법이 제안됐고, 인공신경망의 은닉계층을 대상으로 텐서 병렬화를 적용한 메시-텐서플로가 이를 최초로 딥러닝 모델에 적용한 사례였다.아마존 세이지메이커(Amazon SageMaker)는 지원 모델 형상에 대한 유연성을 높이고 모델의 분할 영역 간 통신 횟수를 줄인 최적화 알고리즘을 적용해 모델 병렬화 기능을 일반화했다.",
        "gentime": "2023-02-17T23:30:14.000Z",
        "img": "https://image.ajunews.com/content/image/2023/02/18/20230218082753467637.jpg",
        "link": "https://www.ajunews.com/view/20230218081024222",
        "companytag": {},
        "imagelist": "n",
        "keywords": [
            "주제",
            "옮겨간다",
            "초거대",
            "하드웨어",
            "모델",
            "지상주의에서",
            "연구",
            "병렬화",
            "기술",
            "연산",
            "성능",
            "병렬화를",
            "효율화자동화로",
            "연구자들은",
            "모델을",
            "텐서",
            "ai"
        ],
        "GPT4": 0,
        "트랜스포머": 4,
        "사용량": 2,
        "GPT4_트랜스포머_사용량": 6,
        "차트이미지경로": "",
        "tvcharturl": ""
    },
    {
        "title": "챗GPT 이제 한국어도 척척 답변오픈AI 차세대 AI GPT4 전격 공개. ",
        "newstext": "gpt-4는 챗gpt의 근본 기술인 gpt-3.5와 비교해 ai의 언어 생성 능력이 15% 이상 향상됐고, 영어로만 제대로 된 답변을 하던 gpt-3.5와 달리 한국어를 포함한 27개 언어로 자연스러운 답변을 하는 것이 특징이다. 구글, 페이스북 등 경쟁 사업자가 연내 초거대 언어모델 출시를 예고한 상황에서 재빠르게 차세대 언어모델을 선보임으로써 자연어 처리 분야에서 경쟁자와 큰 격차가 있음을 입증하려는 것이 샘 앨트먼 오픈ai ceo의 전략이다.14일(현지시간) 오픈ai는 차세대 언어모델인 gpt-4를 자사 홈페이지를 통해 공개하고 유료 구독 서비스인 '챗gpt 플러스'를 통해 사용할 수 있다고 밝혔다.gpt-4는 gpt-3.5와 비교해 언어 생성 능력이 더욱 향상되고 이미지를 인식(컴퓨터 비전)할 수 있는 기능이 추가된 것이 특징이다.이를 두고 오픈 ai는 gpt-4는 다양한 시험과 학술 벤치마크에서 인간 수준의 성능을 보여주는 초거대 멀티 모달 ai(large multimodal model)로, 미국 변호사 시험에서 하위 10%의 성적을 낸 gpt-3.5와 달리 상위 10% 점수를 받을 수 있을 정도로 언어 능력을 향상했다고 밝혔다.이어 한 번에 처리할 수 있는 단어량을 3000개에서 2만5000개로 8배 이상 확대(영어 기준)함으로써 이용자가 더 자세하고 긴 맥락의 답변을 얻을 수 있게 됐다고 강조했다. 이는 언어 생성 능력이 다른 딥러닝(인공신경망) 기술보다 우수하지만, 긴 문장 생성에 약점을 보인 트랜스포머 모델의 문제점을 해결한 것이다.오픈ai는 과거 gpt3에서 gpt-3.5로 ai 모델을 업그레이드하는 데 2년이 넘는 시간이 필요했던 것과 달리 gpt-3.5에서 gpt-4로 모델을 강화하는 것에는 불과 반년밖에 걸리지 않았다. 이는 오픈ai에 대규모 투자를 하고 클라우드를 통해 대규모 ai 반도체 인프라(엔비디아 gpu팜)를 제공한 마이크로소프트와 긴밀한 협력이 있었기에 가능한 일이다.오픈ai는 회사는 지난 2년 동안 전체 딥러닝 스택을 재구축했으며 (초거대 ai 모델 실행을 위한) 작업 부하를 최소화하기 위해 마이크로소프트와 클라우드 기반 슈퍼컴퓨터를 공동 설계했다며 이를 통해 gpt-4 학습 과정은 전례 없이 안정적이었으며 ai 모델의 학습 성능을 사전에 정확하게 예측할 수 있는 최초의 대형 모델이 됐다고 설명했다.이용자는 챗gpt 플러스에 가입하면 gpt-4 기반 차세대 챗gpt를 사용할 수 있다. 다만 gpt-4 기반 챗gpt는 클라우드 서버 부하로 인해 현재 사용량이 4시간에 질문 100개로 제한되어 있고, 사용 한도가 꽉 차면 gpt-3.5 기반으로 사용해야 한다. 오픈ai는 지속해서 ai 모델을 최적화하고 ai 반도체를 확충함으로써 일일 사용량을 확대할 계획이라고 밝혔다.챗gpt 무료 이용자는 gpt-4 기반 챗gpt를 사용할 수 없다. 기업과 개발자는 gpt-4 유료 api 사용 신청을 함으로써 gpt-4와 자사 서비스를 연결할 수 있다.오픈ai는 gpt-4의 언어 능력을 두고 일상적인 대화에선 (gpt-3.5와) 큰 차이를 느낄 수 없지만 전문적인 질문을 하면 차이가 나타난다며 더 안정적이고 창의적이며 미묘한 질문에 대해 답변한다고 밝혔다.일례로 gpt-3.5는 미국 변호사 시험에서 400점 만점에 213점을 받았지만, gpt-4는 400점 만점에 298점을 받아 법률 지식을 한층 끌어올렸다. 미국 수학능력시험인 sat의 경우 읽기 및 쓰기의 경우 800점 만점 기준 670점에서 710점으로 향상됐고, 특히 gpt-3.5의 약점으로 지적받은 수학 능력의 경우 590점에서 700점으로 크게 향상됐다. 의학지식 자가 진단도 정답률이 53%에서 75%로 향상됐다.gpt-4는 다양한 언어 데이터를 학습함으로써 영어 외에 다른 언어에서도 gpt-3.5를 넘어서는 답변 능력을 보여주는 게 특징이다. 먼저 영어 답변 능력은 초거대 ai의 자연어 처리 능력을 보여주는 mmlu 벤치마크 기준 70.1%에서 85.5%로 향상됐다. 엉뚱한 답변을 하기 일쑤였던 한국어 답변 능력도 77.0%로 나와 gpt-3.5에 영어로 질문할 때보다 더 자세하고 정확한 답변을 얻을 수 있게 됐다. 답변 능력이 70%를 넘는 언어만 25개에 이른다. mmlu 벤치마크는 57개 주제 1만4000여개의 질문을 하고 이에 대한 정답률을 확인함으로써 초거대 ai의 언어 능력을 검증하는 테스트다.또 오픈ai는 다방면으로 활용할 수 있는 트랜스포머 모델의 특징을 살려 gpt-4에 자연어 처리뿐 아니라 이미지를 이해할 수 있는 능력(컴퓨터 비전)도 추가했다. 이용자가 업로드한 이미지를 보고 이에 맞는 최적의 답변을 한다. 다만 이미지 이해하기는 시험 기능으로 이용자에게 바로 제공하지는 않는다.오픈ai는 gpt-4가 gpt-3.5의 단점으로 지적받은 '환각 오류'를 완전히 해결하지는 못했다고 강조했다. 환각 오류란 ai가 사실(팩트)과 다른 것을 마치 진실인 것처럼 강한 확신을 담아 답변하는 문제를 말한다. 때문에 gpt-4를 통해 얻은 답변이라도 실제 업무나 논문 등에 활용하려면 강력한 팩트 체크 과정을 거쳐야 한다. 다만 gpt-4는 오픈ai가 실시한 적대적 사실성 평가에서 gpt-3.5보다 40% 높은 점수를 받아 환각 오류를 상당 부분 줄이는 데 성공했다.ai의 허점을 찌르는 질문을 함으로써 위험한 답변과 부정확한 정보, 악성 코드 등을 얻는 문제 해결에도 큰 노력을 기울였다. 오픈ai는 ai 보정, 사이버보안, 의학, 사회 안전 등 다양한 분야 전문가 50명과 함께 ai 모델이 위험한 답변을 하지 않도록 한층 강화한 안전 필터를 만들어 gpt-4에 적용했다. 이를 통해 ai 모델이 허용되지 않는 요청에 대한 답변에 응답하는 경향을 82% 줄였다.다만 2021년 9월 이전 정보만 정확히 답변하고 그 이후 정보는 제한적으로만 답변하는 문제는 그대로다. 답변 데이터를 최신화하는 일정은 아직 공개하지 않았다.샘 앨트먼 오픈ai ceo는 트위터를 통해 gpt-4는 여전히 결함이 있고 제한적이다. 하지만 더 많이 사용해보니 처음 사용할 때보다 더 인상적이다라고 밝혔다.한편 오픈ai는 듀오링고, 비마이아이즈, 스트라이프, 모건스탠리 등 미국 기업과 스타트업이 gpt-4를 자사 업무와 서비스에 도입하기로 했다고 밝히며 초거대 ai 수익화에도 속도를 내고 있음을 강조했다.",
        "summary": "   오픈AI는 지속해서 AI 모델을 최적화하고 AI 반도체를 확충함으로써 일일 사용량을 확대할 계획이라고 밝혔다.챗GPT 무료 이용자는 GPT-4 기반 챗GPT를 사용할 수 없다.엉뚱한 답변을 하기 일쑤였던 한국어 답변 능력도 77.0%로 나와 GPT-3.5에 영어로 질문할 때보다 더 자세하고 정확한 답변을 얻을 수 있게 됐다.오픈AI는 AI 보정, 사이버보안, 의학, 사회 안전 등 다양한 분야 전문가 50명과 함께 AI 모델이 위험한 답변을 하지 않도록 한층 강화한 안전 필터를 만들어 GPT-4에 적용했다.이를 통해 AI 모델이 허용되지 않는 요청에 대한 답변에 응답하는 경향을 82% 줄였다.다만 2021년 9월 이전 정보만 정확히 답변하고 그 이후 정보는 제한적으로만 답변하는 문제는 그대로다.하지만 더 많이 사용해보니 처음 사용할 때보다 더 인상적이다라고 밝혔다.한편 오픈AI는 듀오링고, 비마이아이즈, 스트라이프, 모건스탠리 등 미국 기업과 스타트업이 GPT-4를 자사 업무와 서비스에 도입하기로 했다고 밝히며 초거대 AI 수익화에도 속도를 내고 있음을 강조했다.",
        "gentime": "2023-03-14T20:40:24.000Z",
        "img": "https://image.ajunews.com/content/image/2023/03/15/20230315053456689078.jpg",
        "link": "https://www.ajunews.com/view/20230315053003617",
        "companytag": {
            "#세하": 2
        },
        "imagelist": "n",
        "keywords": [
            "언어",
            "ai",
            "답변을",
            "통해",
            "전격",
            "수",
            "척척",
            "한국어도",
            "오픈ai는",
            "공개",
            "이제",
            "답변",
            "챗gpt",
            "차세대",
            "있는",
            "초거대",
            "gpt4",
            "더",
            "답변오픈ai"
        ],
        "GPT4": 0,
        "트랜스포머": 2,
        "사용량": 2,
        "GPT4_트랜스포머_사용량": 4,
        "차트이미지경로": "",
        "tvcharturl": ""
    },
    {
        "title": "AI머신러닝이 뿜어내는 엄청난 탄소배출량 어이할꼬왜 그럴까. ",
        "newstext": "인종·성별을 차별한 조치라는 의견이 지배적이었지만 그에 앞서 가장 큰 원인은 그가 지금껏 구글의 ai모델 개발 시 발생한 여러 문제점을 짚은 논문 때문이었다.게브루 연구팀이 논문에서 밝힌 내용 중 하나는 ai모델 훈련과 이에 따른 탄소배출량의 상관관계였다. 테크엑스플로러는 15일(현지시간) 현재까지 ai 개발과 훈련과정에서 얼마나 탄소가 배출되고 그 이유가 무엇인지 보도했다. 이어 향후 어떠한 방식으로 개선돼야 하는지에 관해서도 제시했다.ai는 알고리즘을 이해하는 법을 익힐 때까지 엄청난 양의 데이터를 읽어낸다. 이 훈련은 인간이 학습하는 방식과 비교해 매우 비효율적이다. 현대 ai는 인간 뇌 속 뉴런(신경세포)을 모방한 수학적 연산인 인공 신경망을 사용한다.각각의 인공 신경망을 학습한 결과는 가중치(파라미터) 값으로 축적된다. 이 가운데 어떤 단어나 텍스트는 일부분 가려져있어 ai가 추측할 수 있다.한 예로 우리집 강아지는 정말 귀엽다는 문장에서 몇 개의 단어를 숨긴다. 이를 처음 본 ai는 달라진 패턴에 적응하지 못해 잘못 이해할 것이다. 그러나 반복해서 보여주고 여러 번 조정한 후에는 파라미터가 변경되고 데이터에서 새로운 패턴을 수집하기에 이른다.2018년 공개된 구글의 버트(bert)는 언어처리 태스크를 양방향으로 사전학습하는 최초의 대규모 언어모델로 큰 주목을 받았다. 버트는 이 데이터세트를 평균 40번 반복해 읽었다. 비교를 하자면 대화를 배우기 시작하는 평균연령 5세 아이들은 4500만 단어를 듣고 말하며 학습한다. 이는 버트보다 약 3000배 적은 수치라고 한다.대규모 언어모델을 만드는 데 훨씬 더 많은 비용이 드는 이유는 이같은 훈련 과정이 개발 과정 중 여러 번 발생하기 때문이다. 연구진은 뉴런 수를 비롯 뉴런 사이를 잇는 연결 수, 파라미터가 얼마나 빨리 변하는지 파악하기 위해 끊임없이 ai를 훈련시킨다. 더 많은 조합을 시도할수록 네트워크가 높은 정확도를 달성할 가능성도 높아진다.미국 매사추세츠 주립대 애머스트 캠퍼스 연구진은 언어모델 훈련 중 사용되는 공통 하드웨어의 전력 소비량을 측정해 하나의 ai모델을 개발하는 데 드는 에너지 비용을 추정했다. 엠마 스트루벨 박사 연구진은 구글이 버트를 훈련시키는 동안 1438lb(약 652kg)의 이산화탄소를 발생시켰는데 이는 비행기가 뉴욕에서 샌프란시스코를 왕복으로 오갈 때 뿜어내는 양과 같다고 밝혔다. 이 내용은 게브루 연구팀이 논문에서 인용하기도 했다.또 게브루 연구팀은 논문에 구글이 개발한 언어모델 트랜스포머의 경우, 2억1300만개 파라미터를 갖고 있고 학습 과정에서 62만6155lbs(약 28만4000kg)의 이산화탄소를 발생시킨 것을 밝혔다.ai모델은 인간이 실제 필요한 것보다 매년 더 크게 성장한다. 구글의 gpt-2는 네트워크에 15억개의 파라미터를 갖고 있다. 올해 발표된 gpt-3는 무려 1750억개 파라미터로 탄생한 모델이다. 늘어나는 파라미터 수는 곧 그만큼의 훈련을 거듭하는 동안 에너지 사용량이 큰 비중을 차지했다는 의미이기도 하다.인간이 100% 재생 에너지원으로 전환하지 않는 한 ai 개발은 온실 가스 배출을 줄이고 기후 변화를 늦추려는 세계 각국 정부목표와 부딪힌다. 뿐만 아니라 매년 증가하는 연구개발 비용도 문제점으로 자리잡고 있다. 소수의 엄선된 연구소만이 ai모델 개발에 착수하게 되는 것이다.전문가들은 비용문제의 경우 향후 효율적인 훈련방법이 개발된다면 그만큼 낮아질 것으로 기대한다. 한 예로 데이터센터의 에너지 사용량은 최근 몇 년 동안 폭발적으로 증가할 것으로 예측됐지만 하드웨어와 냉각 효율 개선으로 인해 실제로 발생하지는 않았다.보스턴 대학 케이트 사엔코 박사는 가중치를 공유하거나 네트워크의 여러 부분에서 동일한 가중치를 사용해 ai 모델을 작게 만드는 방법을 연구하고 있다. 일명 형태변환 네트워크(shapeshifter network)다. 사엔코에 따르면 이러한 방법은 작은 무게 집합이 어떤 형태나 구조의 더 큰 네트워크로 재구성되기 때문에 에너지 발생율이 적다고 한다.사엔코는 앞으로 ai 커뮤니티는 에너지 효율적인 ai 개발모델을 모색하는 데 더 많은 투자를 해야 한다고 강조했다. 그렇지 않으면 막강한 자본력을 갖고 있는 소수의 it기업에 소속된 소소의 선택된 사람들만이 ai를 지배하게 될 위험이 있다고 경고했다. 인센티브 제도로 기업의 공익적 활동 유도해야",
        "summary": "   인종·성별을 차별한 조치라는 의견이 지배적이었지만 그에 앞서 가장 큰 원인은 그가 지금껏 구글의 AI모델 개발 시 발생한 여러 문제점을 짚은 논문 때문이었다.대규모 언어모델을 만드는 데 훨씬 더 많은 비용이 드는 이유는 이같은 훈련 과정이 개발 과정 중 여러 번 발생하기 때문이다.보스턴 대학 케이트 사엔코 박사는 가중치를 공유하거나 네트워크의 여러 부분에서 동일한 가중치를 사용해 AI 모델을 작게 만드는 방법을 연구하고 있다.사엔코에 따르면 이러한 방법은 작은 무게 집합이 어떤 형태나 구조의 더 큰 네트워크로 재구성되기 때문에 에너지 발생율이 적다고 한다.사엔코는 앞으로 AI 커뮤니티는 에너지 효율적인 AI 개발모델을 모색하는 데 더 많은 투자를 해야 한다고 강조했다.",
        "gentime": "2020-12-16T07:30:16.000Z",
        "img": "https://cdn.aitimes.com/news/thumbnail/202012/134905_132983_4140_v150.jpg",
        "link": "http://www.aitimes.com/news/articleView.html?idxno=134905",
        "companytag": {},
        "imagelist": "n",
        "keywords": [
            "게브루",
            "여러",
            "탄소배출량",
            "엄청난",
            "어이할꼬왜",
            "에너지",
            "있다",
            "더",
            "뿜어내는",
            "큰",
            "이",
            "ai를",
            "ai머신러닝이",
            "그럴까",
            "중",
            "ai"
        ],
        "GPT4": 0,
        "트랜스포머": 1,
        "사용량": 2,
        "GPT4_트랜스포머_사용량": 3,
        "차트이미지경로": "",
        "tvcharturl": ""
    },
    {
        "title": "더 똑똑해진 GPT4 등장생성AI 시장 경쟁 나날이 격화. ",
        "newstext": "   인공지능(ai) 챗봇 '챗gpt'로 최근 급격히 성장한 '생성ai' 시장에서 기업들의 주도권 경쟁이 격화하고 있다. 챗gpt 개발사 오픈ai가 현재 선두주자로 두각을 나타내는 가운데 구글·메타 등 해외 빅테크들도 생성ai 시장에 본격적으로 발을 들였다.국내 it업체들도 시장 공략에 속도를 내는 상황이다. sk텔레콤(skt)·kt·lg유플러스 등 통신사와 네이버·카카오 등 포털업체 등이 핵심 주자다. 이들 업체는 초거대 언어모델 기반 ai 챗봇 서비스를 개발하거나 고도화하는 데 집중하고 있다.15일 업계에 따르면 오픈ai는 전날 차세대 자연어처리(nlp) 모델인 gpt-4를 공개했다. gpt-4는 챗gpt의 근본 기술인 gpt-3.5와 비교해 ai의 언어 생성 능력이 15% 이상 향상됐다. 영어로만 제대로 된 답변을 하던 gpt-3.5와 달리 한국어를 포함한 27개 언어로 자연스러운 답변을 하는 것이 특징이다.오픈ai가 이러한 기술 역량 강화로 빠르게 시장 선두 굳히기에 나서자 국내 기업들 발등에도 불이 떨어졌다. 이젠 한국어 특화를 강점으로 내세우는 것만으로는 시장 경쟁력 확보가 어려워질 전망이기 때문이다. 더 차별화된 서비스로 이용자의 마음을 사로잡는 것이 핵심 과제로 부상했다.gpt-4는 gpt-3.5 대비 언어 생성 능력이 향상됐다. 이미지를 인식(컴퓨터 비전)할 수 있는 기능도 추가됐다. 오픈ai 측은 이를 두고 여러 시험과 학술 벤치마크에서 인간 수준의 성능을 보여주는 초거대 멀티 모달 ai라고 강조했다.특히 미국 변호사 시험에서 하위 10%의 성적을 낸 gpt-3.5와 달리 상위 10% 점수를 받을 수 있을 정도로 언어 능력이 높아졌다. 한 번에 처리할 수 있는 단어 수는 3000개에서 2만5000개로 8배 이상 확대(영어 기준)됐다.이를 통해 이용자가 더 자세하고 긴 맥락의 답변을 얻을 수 있게 됐다는 설명이다. 긴 문장 생성에 약점을 보인 트랜스포머 모델의 문제점을 해결한 것이다. 오픈ai가 클라우드 기반 ai 반도체 인프라를 제공한 마이크로소프트(ms)와 긴밀하게 협력한 성과다.이용자는 챗gpt 플러스에 가입하면 gpt-4 기반 차세대 챗gpt를 사용할 수 있다. 다만 gpt-4 기반 챗gpt는 클라우드 서버 부하로 인해 현재 사용량이 4시간에 질문 100개로 제한돼 있다. 사용 한도가 꽉 차면 gpt-3.5 기반으로 사용해야 한다.샘 올트먼 오픈ai 최고경영자(ceo)는 본인 소셜미디어 계정에서 gpt-4는 여전히 결함이 있고 제한적이지만 사용할수록 더 인상적인 모델이라고 평가했다. 오픈ai는 ai 모델을 지속적으로 최적화하고 ai 반도체를 확충함으로써 일일 사용량을 확대할 계획이다.오픈ai는 gpt-4의 언어 능력을 두고 일상적인 대화에선 (gpt-3.5와) 큰 차이를 느낄 수 없지만 전문적인 질문을 하면 차이가 나타난다며 더 안정적이고 창의적이며 미묘한 질문에 대해 답변한다고 밝혔다.일례로 법률 지식 역량을 들 수 있다. gpt-3.5는 미국 변호사 시험에서 400점 만점에 213점을 받았지만, gpt-4는 400점 만점에 298점을 받았다. 또한, 미국 수학능력시험(sat) 읽기·쓰기의 경우 800점 만점 기준 670점에서 710점으로 올랐다. 특히 gpt-3.5의 약점으로 지적 받아온 수학 부문은 590점에서 700점으로 크게 향상됐다. 의학 지식 자가 진단도 정답률이 53%에서 75%로 향상됐다.gpt-4는 영어 외에 다른 언어에서도 gpt-3.5를 넘어서는 답변 능력을 보여준다. 초거대 ai의 nlp 능력을 검증하는 mmlu 벤치마크 기준 한국어 답변 능력은 77.0%로 올랐다. 이에 따라 gpt-3.5에 영어로 질문할 때보다 더 자세하고 정확한 답변을 얻을 수 있게 됐다. 답변 능력이 70%를 넘는 언어만 25개에 이른다.오픈ai는 gpt-4에 nlp뿐 아니라 이미지를 이해할 수 있는 능력(컴퓨터 비전)도 추가했다. 이용자가 업로드한 이미지를 보고 이에 맞는 최적의 답변을 제공하는 식이다. 다만 이 기능은 현재 시범용으로 지원 중이라 이용자들은 사용이 어렵다.gpt-4의 한계도 여전하다. 오픈ai는 gpt-4가 gpt-3.5의 단점인 '환각 오류'를 완전히 해결하지 못했다고 언급했다. 환각 오류란 ai가 사실과 다른 것을 마치 진실인 것처럼 강한 확신을 담아 답변하는 문제를 말한다. 때문에 gpt-4를 통해 얻은 답변이라도 실제 업무나 논문 등에 활용하려면 엄격한 사실 확인 단계를 거쳐야 한다.한국어 능력이 강화된 챗gpt가 나온 상황에서 국내 업체들의 대응은 더 빨라질 수밖에 없다.skt는 지난달 12일 자체 구축한 슈퍼컴퓨터 '타이탄' 성능을 두 배 이상으로 강화했다고 밝혔다. 타이탄에 활용되는 엔비디아 a100 그래픽처리장치(gpu)를 1040개로 증설한 것. 기존 대비 두 배 이상 키운 규모다.더 정교한 초거대 ai 구현에 나서기 위한 목적이다. skt는 이번 인프라 확대로 더 광범위한 데이터를 빠르고 정확하게 처리할 수 있는 컴퓨팅 성능을 확보하게 됐다. 타이탄을 기반으로 서비스를 제공하는 gpt-3 기반 에이닷도 기존보다 더 정교하게 학습할 수 있다. 에이닷은 현재보다 두 배 이상 규모 모델로 고도화 하는 것이 가능해졌다.kt는 한국과학기술원(kaist)과 ai 공동 연구를 확대하고 있다. 가장 최근 사례를 보면 지난달 21일 양측 공동연구센터 워크숍 자리를 마련해 ai 관련 기술과 서비스, 연구과제 목표와 성과, 향후 계획을 점검했다. lg유플러스의 경우 lg ai연구원에서 개발한 초거대 ai '엑사원'을 iptv 등 서비스에 적용하기 위한 방안을 찾고 있다.네이버·카카오는 한국어 데이터를 대규모로 축적한 강점을 바탕으로 초거대 ai 서비스를 내놓을 예정이다. 네이버클라우드는 오는 7월 한국어 데이터 학습을 강화한 챗gpt 버전 '하이퍼클로바x' 공개를 앞두고 있다. 이 과정에서 삼성전자와 개발한 ai 반도체를 자체 인프라에 탑재하는 등 인프라도 강화하는 추세다.카카오의 기술 개발 자회사 카카오브레인은 이달 초 온라인 채용설명회를 진행하고 대규모 ai 인력 채용에 나선 상태다. 모집 분야는 머신러닝(ml)옵스, 프론트엔드, 백엔드, 서비스 기획, 사용자경험(ux), ai 리서치 등이며 총 두 자릿수 규모로 경력직을 채용할 예정이다. 조만간 추가 분야에 대한 신입직 등 채용도 실시한다. 김일두 카카오브레인 대표는 사내 gpu를 연내 1000대 추가 활용하는 등 인프라 투자 계획도 발표했다.구글·메타 등 해외 업체들은 챗gpt에 대항해 최근 잇따라 생성ai 서비스를 선보이고 있지만 서비스 수준은 챗gpt에 못 미친다는 평가를 받는다. 구글이 지난달 선보인 ai 챗봇 서비스 '바드'는 출시 행사에서 오답을 제시하며 논란이 된 바 있다. 페이스북 모회사 메타도 최근 자체 언어모델 '라마'를 공개했지만 연구용 목적으로 쓰여 제한적이다.국내 ai 전문가들은 gpt-4가 여러 강점을 지닌 모델이라고 평가했다. ai 업체 업스테이지의 김성훈 대표는 gpt-4는 이미지를 보고 이해할 수 있으며 더 많은 데이터로 학습했기 때문에 (이용자가 gpt-4를) 속이는 일은 더 어려울 것 이라며 한국어를 포함한 다국어 지원이 가능한 것도 장점이라고 말했다.이어 gpt-4는 다양한 성격을 갖고 있어 이용자가 이 모델에 기반한 챗gpt 성격을 본인이 원하는 대로 바꿀 수 있게 됐다고 강조했다. 가령 '고정된 장황함, 어조, 스타일이 있는 고전적인 챗gpt 성격'을 요구하면 그에 따른 답변을 제공한다고 설명했다.다만 생성ai 시장에서 살아남기 위해 서비스 차별화는 필수가 될 전망이다. 한 업계 관계자는 이번 gpt-4 출시로 인해 국내 업체들은 더 차별화된 서비스를 제공해 경쟁력을 확보해야 할 것이라며 gpt-4가 방대한 데이터와 파라미터(매개변수)를 통해 한국어조차 좋은 성능을 보여줄 것으로 예상된다. 국내 업체들도 언어 특화 등 부분뿐 아니라 이러한 기술 발전을 활용하고 시장의 변화에 빠르게 대응해 지속적인 혁신을 추구하는 것이 중요하다고 말했다.한편, 오픈ai 투자사인 마이크로소프트(ms)는 이날 자사 검색엔진 빙에 이번 gpt-4를 탑재할 계획이라고 밝혔다. 구글 클라우드는 자체 생성 ai를 기반으로 구글 워크스페이스와 개발자를 지원하는 신규 ai 제품·기능을 발표하기도 했다.",
        "summary": "   오픈AI가 클라우드 기반 AI 반도체 인프라를 제공한 마이크로소프트(MS)와 긴밀하게 협력한 성과다.이용자는 챗GPT 플러스에 가입하면 GPT-4 기반 차세대 챗GPT를 사용할 수 있다.답변 능력이 70%를 넘는 언어만 25개에 이른다.오픈AI는 GPT-4에 NLP뿐 아니라 이미지를 이해할 수 있는 능력(컴퓨터 비전)도 추가했다.기존 대비 두 배 이상 키운 규모다.더 정교한 초거대 AI 구현에 나서기 위한 목적이다.SKT는 이번 인프라 확대로 더 광범위한 데이터를 빠르고 정확하게 처리할 수 있는 컴퓨팅 성능을 확보하게 됐다.LG유플러스의 경우 LG AI연구원에서 개발한 초거대 AI '엑사원'을 IPTV 등 서비스에 적용하기 위한 방안을 찾고 있다.네이버·카카오는 한국어 데이터를 대규모로 축적한 강점을 바탕으로 초거대 AI 서비스를 내놓을 예정이다.",
        "gentime": "2023-03-15T11:24:29.000Z",
        "img": "https://image.ajunews.com/content/image/2023/03/15/20230315184918945381.jpg",
        "link": "https://www.ajunews.com/view/20230315114910966",
        "companytag": {
            "#카카오": 5,
            "#세하": 2,
            "#삼성전자": 1
        },
        "imagelist": "n",
        "keywords": [
            "경쟁",
            "격화",
            "초거대",
            "시장",
            "등장생성ai",
            "gpt4",
            "있다",
            "더",
            "답변을",
            "챗gpt",
            "수",
            "나날이",
            "등",
            "언어",
            "있는",
            "똑똑해진",
            "ai"
        ],
        "GPT4": 0,
        "트랜스포머": 1,
        "사용량": 2,
        "GPT4_트랜스포머_사용량": 3,
        "차트이미지경로": "",
        "tvcharturl": ""
    },
    {
        "title": "GPU 1만개로 만든 그 답변 수천 가구가 쓸 전력 삼켰다. ",
        "newstext": "    박정호 sk하이닉스 대표이사 부회장이 15일 서울 중구 한국프레스센터에서 ai시대, 한국의 디지털·반도체 산업과 대학교육을 주제로 열린 한림대학교 도헌학술원 개원기념 심포지엄에서 기조발제를 하고 있다. 2023.2.15 sk하이닉스 제공챗gpt의 등장으로 인공지능(ai)은 디지털 시대에 거스를 수 없는 대세가 됐다. ai는 스스로 판단해 작업을 최적화, 효율화하고 많은 분야에서 에너지를 절감할 것으로 예상된다. 하지만 ai 스스로는 개발, 구축, 운영에 천문학적인 비용이 들어가며, 전력 소모가 극심하다. 모든 업계가 환경·사회·지배구조(esg) 경영을 부르짖는 시대를 이끄는 ai가, 정작 엄청난 에너지를 소비하는 역설적인 상황이다.●skt 에이닷 gpu 1040개 사용초거대 ai는 복잡한 연산을 동시다발로 하기에 고성능 처리장치를 필요로 한다. 그런데 고성능 처리장치는 전기를 많이 쓴다. 초거대 ai 운용엔 대체로 중앙처리장치(cpu)가 아닌 그래픽처리장치(gpu)가 쓰인다. ai반도체 시장점유율 90% 이상을 차지하는 엔비디아의 최신 gpu a100의 소비전력은 모델에 따라 300400w(와트)이며 시간당 전력 소비량은 300400wh(와트시)이다. 초거대 ai 운용엔 gpu가 수백수천개 사용된다. sk텔레콤의 초거대 ai 서비스 에이닷의 기반인 슈퍼컴퓨터 타이탄엔 a100이 1040개 들어간다. 챗gpt 구동엔 a100 1만개가 사용되는 것으로 알려졌다.초거대 ai 운용에 필수인 인터넷데이터센터(idc)도 대표적인 고전력 시설이다. 산업통상자원부의 지난달 자료에 따르면 idc 한 개당 평균 연간 전력 사용량은 25gwh(기가와트시)로, 4인가구 기준 6000가구가 사용하는 전력량과 같은 수준이다.애초에 ai 연산용이 아니라 그래픽 처리 속도를 높이기 위해 만들어진 gpu는 데이터를 한 번에 대량으로 처리할 수 있지만, 값이 비싸고 전력도 많이 소비한다. 이에 신경망처리장치(npu)라는 ai 전용 반도체 개발이 gpu의 문제를 해결할 대안으로 주목받았다. sk텔레콤이 지분 50%를 보유한 사피온이 2020년 발표한 npu x220은 지난해 ai 구동 성능 테스트에서 엔비디아의 a2를 뛰어넘은 바 있다. 그러면서도 65w에 불과한 소비전력은 고성능 cpu들과 비교해도 적은 축에 들어간다. 사피온은 올해 전작 대비 성능을 약 4배 향상시킨 신제품 x330을 출시할 예정이다. kt와 ai 드림팀을 이룬 반도체 회사 리벨리온도 아톰이라는 npu를 개발했다. 아톰 역시 소비전력이 60150w에 불과하며 챗gpt의 원천 기술인 트랜스포머 계열 자연어 처리 기술을 지원한다.개발 환경 등 현재 ai 생태계 자체가 gpu 체제에서 세워진 만큼 npu 시장이 짧은 시일 내에 활성화되긴 어려울 것으로 보인다. 이에 gpu와 함께 칩셋을 이루며 방대한 데이터를 빠르게 처리하는 고성능 d램인 고대역폭메모리(hbm)가 ai 반도체의 효율을 극대화할 수 있는 방책으로 떠올랐다.●침체된 반도체 시장 훈풍 기대감sk하이닉스의 3세대 hbm3 제품은 a100에 탑재되고 있으며, 엔비디아의 차기 gpu 신제품에 4세대 hbm4가 적용될 전망이다. 삼성전자는 hbm에 ai 프로세서를 결합한 지능형메모리(hbm-pim) 제품을 amd의 최신 gpu 제품에 공급하고 있다. 삼성전자에 따르면 hbm-pim을 활용하면 기존 gpu 가속기 대비 평균 성능이 2배 증가하고 에너지 소모는 50% 감소한다",
        "summary": "   초거대 AI 운용엔 대체로 중앙처리장치(CPU)가 아닌 그래픽처리장치(GPU)가 쓰인다.AI반도체 시장점유율 90% 이상을 차지하는 엔비디아의 최신 GPU A100의 소비전력은 모델에 따라 300400W(와트)이며 시간당 전력 소비량은 300400Wh(와트시)이다.초거대 AI 운용엔 GPU가 수백수천개 사용된다.SK텔레콤의 초거대 AI 서비스 에이닷의 기반인 슈퍼컴퓨터 타이탄엔 A100이 1040개 들어간다.삼성전자는 HBM에 AI 프로세서를 결합한 지능형메모리(HBM-PIM) 제품을 AMD의 최신 GPU 제품에 공급하고 있다.",
        "gentime": "2023-02-26T09:30:30.000Z",
        "img": "https://img.seoul.co.kr/img/upload/2023/02/27/SSC_20230227060740.jpg",
        "link": "https://www.seoul.co.kr/news/newsView.php?id=20230227002002&wlog_tag3=naver",
        "companytag": {
            "#삼성전자": 2
        },
        "imagelist": "n",
        "keywords": [
            "전력",
            "것으로",
            "쓸",
            "만든",
            "1만개로",
            "초거대",
            "반도체",
            "답변",
            "gpu",
            "있다",
            "엔비디아의",
            "고성능",
            "수",
            "수천",
            "가구가",
            "삼켰다",
            "그",
            "ai"
        ],
        "GPT4": 0,
        "트랜스포머": 1,
        "사용량": 1,
        "GPT4_트랜스포머_사용량": 2,
        "차트이미지경로": "",
        "tvcharturl": ""
    },
    {
        "title": "인공지능 chatGPT에게 기후위기 해결책 따위는 묻지 않기를. ",
        "newstext": "   메타버스는 가고, 인공지능은 다시 뜨고?지난해 연말부터 관심 폭발이던 대화형 인공지능 chatgpt가 올해에는 더욱 거세다. 온갖 미디어, sns, 심지어 시민들의 일반 대화에서도 chatgpt 주제로 가득찼다. 이 현상은 직업, 정견, 연령 불문인 것 같다. 2022년까지 뜨거운 기술적 주제였던 블록체인이나 메타버스는 까마득한 과거얘기처럼 들릴 정도다.서비스를 공개한 지 5일만에 100만 사용자를 넘었고 2달 만에 월간활성사용자(mau) 수가 1억 명을 돌파했으며, 곧바로 월 20달러 유료서비스에 착수할 정도니 안 그러기도 쉽지 않다. 이에 대해 월스트리트저널은 지난 2월 18일, 암호화폐 대신 ai가 실리콘밸리의 차세대 밴드웨건이 됐다면서, 최근 투자자와 테크기업 경영자는 물론 엔지니어들까지 chatgpt 붐에 편승하기 위해 변신을 서두르고 있다고 꼬집었다.그림1 chatgpt 5일만에 1백만 사용자 돌파새로운 세대의 인공지능 chatgpt의 신화와 실제기존까지의 식별형 인공지능을 넘어 chatgpt같은 생성형 인공지능이 급부상하자 온갖 화려한 상상이 다시 가득해지고 있다. 기존의 학교수업이나 의료와 법률서비스 방식이 근본적으로 바뀔 것이라는 성급한 진단은 그나마 얌전한 편이다. 일반지능(agi)시대가 드디어 왔다고 주장하는가 하면, 지금보다 성능이 10배 이상 개선된 chatgpt4가 출시되면 초지능에 근접하는 특이점(singularity) 도래도 내다볼 수 있다는 주장까지 난무한다. 도대체 chatgpt는 과거의 인공지능과 얼마나 다르길래 이런 열광과 환상적인 전망이 쏟아져 나올까?비영리법인으로 시작했지만 2019년 마이크로소프트의 대규모 자본투자로 영리의 길을 걷고 있는 openai가 개발한 chatgpt(generativepretrainedtransformer)-3.5는, 1750억 개의 매개변수를 갖는 트랜스포머 아키텍쳐 기반의 대형 언어모델(large language model; llm)로 알려졌다.그런데 착각하지 말아야 할 것이 있다. 잘 알려진 딥러닝의 한 유형인 gpt-3모델은 엄밀히 말해 인간의 뇌처럼 스스로 생각하고 말하는 것이 아니라, 다음에 나올 문장 중 가장 자연스러운 단어를 학습하여 자연어를 흉내내는 것이다. 다시 말해서 스스로는 전혀 무슨 말을 하고 있는지 인식하지 못하면서 기존 학습 데이터를 참조로 그럴듯한 말을 조합한다는 얘기다.때문에 아무리 chatgpt가 놀라운 답변을 해내더라도 그것은 기존에 학습한 데이터를 가지고 가장 그럴 듯하게 재구성하는 것에 불과하다. 따라서 생성되는 답변이 거짓일 확률도 얼마든지 있고, 저작권이 문제가 될 수도 있으며, 심지어 유해한 내용까지 담을 수 있다. 혹은 잘못된 답변을 하면서도 틀린 정보도 약장수처럼 솔깃하게 들리도록 자신있게 말하는 바람에 혼란을 주기도 한다.이런 문제들 때문에 openai는 사용자의 의도와 부합되는 모델을 만들기 위해 rlhf 모델을 도입했다. 이 모델은 과거 이루다가 범한 차별과 편향을 피하기 위해 윤리와 도덕적인 질문 등에 대해 chatgpt에게 인간이 직접 훈련을 시키는 지루한 작업을 수행한 것이다(이런 교정과정을 거친 것이 바로 chatgpt3.5다). 아울러 openai는 chatgpt가 작성한 답변의 거짓이 문제가 될 것을 염려해서 이의 진위를 가리는 새로운 ai도 개발 중이라고 한다.또한 chatgpt는 대화의 맥락을 파악하여 답변하는 방식이므로 정확함이 요구되는 수학 계산에 비교적 약한 모습을 보이고 있고, 특히 학습 데이터 중 영어 데이터가 92%에 달하고 한국어 데이터는 고작 0.19%에 불과하여 한글로 묻고 답하면 엉터리 답변이 숱하게 쏟아져 나온다. 이처럼 chatgpt는 자연어 처리가 능숙한 탓으로 일반인들에게 굉장히 친숙하고 세련되게 다가오지만, 근본적으로는 과거의 딥러닝 기반 인공지능과 질적으로 다른 것이라고 볼 수 없다.기존 인공지능에 비해 더 많은 전력 소모, 더 많은 탄소배출물론 chatgpt는 탁월한 자연어 처리, 압도적인 매개변수 개수, 이를 처리하기 위한 대규모 하드웨어 용량 등을 기반으로 과거보다 훨씬 많은 영역에서 인간의 사회경제활동에 개입하게 될 것이다. 때문에 일반지능이나 초지능 진화 같은 근거 없는 환상을 배제하더라도, it개발자들에게는 버그잡기나 문서화 등 고된 일들을 줄여줄 수 있고, 기존 콜센터 등 대화형 고객 서비스는 더 광범위하게 챗봇으로 대체될 것이며, 각종 지식노동에서 기본적인 자료수집이나 초안작업에 다양하게 chatgpt가 활용될 것이다.그런데 이 대목에서 확실하게 살펴봐야 할 대목이 있다. 통상 인간의 어떤 활동을 기계든 인공지능이든 인공적인 것으로 대체하면, 그만큼 에너지와 자원이 더 소모된다는 점이다. 생산과 서비스 현장에서 사람이 해고되고 자동화기계로 대체된다는 얘기는 그만큼 인간의 에너지 대신 다른 에너지가 사용된다는 것이기 때문이다.구체적으로 살펴보자. 구글에서 공개한 탄소배출과 거대인공신경망 학습이라는 논문을 보면, 구글의 언어 번역프레임워크(gshard)은 학습과정에서 24메가와트 에너지와 4.3톤의 이산화탄소를 배출했는데, gpt-3은 그보다 압도적으로 많은 1,287메가와트의 에너지를 사용하고 552톤의 이산화탄소를 배출했다(그림 참조). 당연한 얘기다. 인공지능 성능 향상을 위해 더 많은 학습 데이터를 투입하고, 매개변수 처리를 하고, 이를 위한 cpu, gpu 성능과 숫자가 늘어나게 되어 전력소비와 이산화탄소배출이 계속 증가하게 되기 때문이다. 이 과정에서 절전형 프로세서가 개발된다고 하더라도 전체 사용량이 늘어나는 것은 피하기 어렵다.그림2주요 거대언어모델 학습을 위해 요구되는 전력소비와 탄소배출량chatgpt로 인한 기술경쟁의 진짜 패배자는 누구인가?7년 전 알파고와 이세돌의 바둑 대결을 기억하는가? 사실 에너지 관점에서 이세돌과 알파고의 싸움은 심각하게 불공정했다. 당시 이세돌이라는 인간은 대국을 위해 약 20w의 에너지를 소모했을 것이라고 한다. 그런데 알파고는 이세돌의 약 50만배인 100만w를 사용하였다고 한다. 대국을 위해 1920개 중앙처리장치(cpu)와 280개의 그래픽 프로세서(gpu)를 사용했기 때문이다.우리가 잊고 있는 것이 있다. 어떤 대목에서 보면 인간은 최고의 효율적인 열역학 엔진이다. 인간은 하루에 2천 킬로 칼로리 정도의 에너지만 공급받으면, 청소에서 돌봄, 온갖 육체적 생산노동과, 지식노동, 감정노동까지 평균적인 인간은 우리가 필요로 하는 거의 모든 일을 할 수 있다.그에 비하면 컴퓨터나 인공지능은 특정한 일들만을 우수하게 하는데, 그조차도 인간에 비해 지나치게 비효율적으로 에너지를 소모한다. 그런데도 불구하고 우리는 인간의 역할을 인공지능이 대체하는 것을 보고 환호한다. 효율적인 열역학 엔진을 비효율적인 엔진으로 교체하는데도 말이다.물론 기업 입장에서는 확실한 동기가 있다. 인공지능은 에너지를 많이 잡아먹지만 노동이 고되다고 불평하지도 않고 노동조합 만들겠다고 협박하지도 않을 테니 말이다. 그러니 지금 구글, 페이스북, 아마존 등 거대 플랫폼 기업들이 정신없이 해고와 감원을 하면서도 chatgpt에 열광하며 대규모 투자를 하겠다고 공언하고 있는 것이 아닐까?자원생산성 향상 없는 인공지능 확대는 기후위기 악화 우려이렇듯 현대 경제에서 기업들은 아무런 불만이나 저항도 표시할 수 없는 자연자원에 대해서는, 고갈이나 파괴의 비용을 제대로 지불하지도 않고 일방적으로 자신들의 수익 극대화를 위해 과도하게 싼 가격을 매겨 남용하고 있다. 반면 불만과 저항을 표현할 수 있는 노동의 경우는 온갖 자동화 기술과 인공지능 기술을 동원해 고용을 줄이는 방식을 추구하고 있다.하지만 기후위기 시대에는 노동생산성 향상으로 노동 비용을 줄이는 데 주력할 것이 아니라 일자리를 유지하면서 자원과 에너지의 사용을 줄이는 자원생산성을 향상시키는 쪽에 초점을 두어야 한다. 흔히 기술혁신이 일자리를 줄일 거라고 당연하게 생각하지만 일자리를 강제로 소멸시키는 기술 법칙 같은 것은 없다. 기업가들이 인건비를 줄이겠다고 기술혁신을 주로 노동생산성 향상에 집중했기 때문에 일자리 소멸을 걱정하는 것이다.환경을 고민하는 it개발자 게리 맥거번(gerry mcgovern)는 자신의 책 <월드와이드 쓰레기(world wide waste)>에서, 인간이 문제고 비용을 절감하는 자동화가 해법이라고 생각하는 문화에 대해 비판하면서, 인터넷과 인공지능이 얼마나 기후에 해로운지에 대해 경각심을 가져야 한다고 강조한다. 그의 조사에 따르면 2020년 기준으로 하루에 이메일을 주고받는 건수가 3천억 건 이상이다. 이메일 한 건 처리하는데 탄소배출이 약 4그램쯤 되므로 이메일 때문에 발생하는 탄소배출량이 하루에 무려 10만 톤 정도가 되는 셈이다. 더 문제는 이메일 중에 절반이 전혀 쓸모없는 스팸메일이라는 것이다.우리가 chatgpt에 질문을 하나 할 때마다 수많은 연산과 데이터 처리, 정보의 네트워크 이동이 발생하며, 그때마다 에너지사용과 탄소배출은 폭증하는 것은 필연이다. 그런데도 만약 chatgpt에게 기후위기를 막을 해법을 질문한다면 이는 얼마나 아이러니가 될 것인가? 기후위기를 막지 못하는 것은 인류의 지식이 부족해서가 아니다. 부족한 것은 정치적 의지다. 그러니 chatgpt에 기후위기 해결책 따위는 더 이상 물어보지 않기를 바란다.* <정의로운 경제> 연재 칼럼 링크",
        "summary": "   그런데 착각하지 말아야 할 것이 있다.따라서 생성되는 답변이 거짓일 확률도 얼마든지 있고, 저작권이 문제가 될 수도 있으며, 심지어 유해한 내용까지 담을 수 있다.기존 인공지능에 비해 더 많은 전력 소모, 더 많은 탄소배출물론 chatGPT는 탁월한 자연어 처리, 압도적인 매개변수 개수, 이를 처리하기 위한 대규모 하드웨어 용량 등을 기반으로 과거보다 훨씬 많은 영역에서 인간의 사회경제활동에 개입하게 될 것이다.인공지능 성능 향상을 위해 더 많은 학습 데이터를 투입하고, 매개변수 처리를 하고, 이를 위한 CPU, GPU 성능과 숫자가 늘어나게 되어 전력소비와 이산화탄소배출이 계속 증가하게 되기 때문이다.인간은 하루에 2천 킬로 칼로리 정도의 에너지만 공급받으면, 청소에서 돌봄, 온갖 육체적 생산노동과, 지식노동, 감정노동까지 평균적인 인간은 우리가 필요로 하는 거의 모든 일을 할 수 있다.",
        "gentime": "2023-02-23T01:23:08.000Z",
        "img": "http://www.redian.org/wp-content/uploads/2023/02/11-10.jpg",
        "link": "http://www.redian.org/archive/168869",
        "companytag": {
            "#이루다": 1
        },
        "imagelist": "n",
        "keywords": [
            "것은",
            "해결책",
            "chatgpt에게",
            "위해",
            "기후위기",
            "많은",
            "있다",
            "더",
            "인공지능",
            "수",
            "인간의",
            "할",
            "묻지",
            "것이",
            "않기를",
            "따위는"
        ],
        "GPT4": 0,
        "트랜스포머": 1,
        "사용량": 1,
        "GPT4_트랜스포머_사용량": 2,
        "차트이미지경로": "",
        "tvcharturl": ""
    },
    {
        "title": "AI 리뷰 인텔과 허깅페이스가 함께하는 생성 AI의 컴퓨팅과 지속가능성 과제 해결 및 그 여정. ",
        "newstext": "   로고 편집:본지사용자가 인공지능(ai), 머신러닝 모델 및 데이터 세트를 공유할 수 있는 세계 최대 플랫폼이자 커뮤니티인 허깅 페이스(hugging face)는 인텔의 ai 하드웨어 가속기가 현재 시판 중인 어떤 gpu보다 빠르게 추론을 실행한다는 성능 결과를 지난달 28일 공유했다. 하바나 가우디2는 1,760억 개의 매개변수에서 엔비디아의 a100대비 20% 더 빠른 추론 성능을 보였다.또한 가우디2 서버에서 인기 있는 컴퓨터 비전 워크로드를 실행할 때 동급 a100 기반 서버 대비 1.8배 높은 와트당 처리량을 보여, 뛰어난 전력효율성을 입증했다.현재 챗gpt 등 생성 ai 툴은 업계 내 새로운 가능성을 제시해 기대감을 불러일으켰으나, 해당 모델이 요구하는 컴퓨팅으로 인해 기업들은 컴퓨팅 성능, 비용 및 에너지 효율성에 초점을 맞추고 있다.생성 ai(generative ai) 모델의 규모가 커짐에 따라 데이터 전처리부터 학습 및 추론에 이르기까지 다양하고 복잡한 ai 워크로드 기능의 생산성을 높이는데 전력 효율성이 중요한 요소가 되었다. 개발자는 생성 ai를 포함한 모든 형태의 ai가 잠재력을 최대한 발휘할 수 있도록 유연하고 개방적이며 에너지 효율적이고 지속 가능한 솔루션으로 한 번 구축해 어디나 배포할 수 있어야 한다.ai는 오랫동안 발전해 왔으나 앞으로 훨씬 더 많이 활용되어야 한다. 모든 사람이 ai를 사용할 수 있도록하는 ai 민주화와 지속 가능성을 위한 인텔의 노력은 개방형 생태계를 통해 생성형 ai를 비롯한 기술의 이점을 더 폭넓게 활용할 수 있도록 지원할 예정이다.개발자는 개방형 생태계를 통해 널리 사용되는 오픈 소스 프레임워크, 라이브러리 및 툴에 대한 인텔의 최적화를 통해 어디서나 ai를 개발하고 배포할 수 있다. 인텔의 ai 하드웨어 가속기와 4세대 인텔 제온 스케일러블 프로세서에 내장된 가속기는 성능 및 와트당 성능 향상을 제공하여 생성 ai의 성능, 가격 및 지속 가능성 요구 사항을 충족시킨다.사람이 만든 콘텐츠를 모방할 수 있는 생성 ai는 일상 생활의 여러 측면을 변화시킬 수 있는 놀라운 기회를 제공한다. 그러나 기술이 빠르게 진화함과 동시에 데이터 센터에서 성공적으로 ai를 활용하는데 있어 필수적인 컴퓨팅의 복잡성도 함께 노출하고 있다.인텔은 모든 사람이 기술에 접근하고 기술을 쉽게 확장할 수 있도록 미래를 위해 많은 투자를 하고 있다. 인텔의 리더들은 신뢰, 투명성, 선택권을 기반으로 구축된 개방형ai 생태계를 지원하기 위해 업계 전반의 파트너와 활발하게 협력하고 있다.뛰어난 성능의 오픈 소스 생성 ai 도입생성형 ai는 gpt-3 및 dall-e와 같은 언어 모델을 활용해 왔다. 다만, 인간처럼 대화할 수 있는 생성형 ai 챗봇인 챗gpt에 대한 관심이 증폭되면서, 기존 데이터 센터 아키텍처의 장애물에 대해 주목하게 됐다.또한 인공지능의 잠재력을 최대한 발휘할 수 있는 하드웨어 및 소프트웨어 솔루션의 필요성이 커졌다. 개방형 접근 방식과 이기종 컴퓨팅에 기반한 생성형 ai는 최상의 솔루션을 보다 광범위하게 접근하고 비용 효율적으로 배포할 수 있도록 지원한다. 개방형 생태계는 개발자가 전력, 가격, 성능에 우선순위를 두면서 어디서나 ai를 구축하고 배포할 수 있도록 지원해 생성형 ai의 잠재력을 실현한다.인텔은 복잡성을 제거하면서 인기 있는 오픈 소스 프레임워크, 라이브러리 및 툴을 최적화해 최고의 하드웨어 성능을 이끌어낼 수 있는 생성형ai를 지원하기 위해 노력하고 있다.머신러닝을 위한 최고의 오픈소스 라이브러리인 허깅 페이스는 현재 시중에 나와 있는 어떤 gpu보다 인텔의 ai 하드웨어 가속기에서 더 빠른 추론이 가능하다는 테스트 결과를 공유했다.모델 로고 이미지지난달 13일 발표된 1,760억 개의 매개 변수(parameter)의 세계 최대의 개방형 트랜스포머 기반 다국어 모델 bloomz 모델(논문, bloom: 176b 매개변수 개방 액세스 다국어 언어 모델-다운)에 대한 추론으로 인텔의 하바나 가우디2가 엔비디아 a100-80g보다 20% 더 빠르게 실행된다. bloomz(모델 다운)는 46개 언어와 13개 프로그래밍 언어가 처리 가능하도록 설계됐으며 완벽히 투명하게 만들어졌다. 모델 훈련의 모든 리소스는 전 세계 연구자와 엔지니어가 사용할 수 있으며 문서화되어 있다.70억 개라는 더 적은 매개 변수를 가진 bloomz(bigscience large open-science open-access) 모델을 실행할 경우, 가우디2는 a100-80g보다 3배 빠른 성능을 제공하며, 1세대 하바나 가우디는 a100-80g보다 가격 대비 성능 면에서 확실한 이점을 제공한다. 허깅 페이스 옵티멈 하바나 라이브러리를 사용할 시 가우디 가속기에서 최소한의 코드 변경으로 대규모 llm을 간편하게 배포할 수 있다.인텔 랩 연구원들은 가우디2와 최근 언어 모델에 대한 벤치마크로 제안된 lmentry를 활용해 제로 샷 설정에서 bloomz를 평가했다. bloomz의 정확도는 gpt-3와 유사하게 모델 크기에 따라 확장되며, 아래 그래픽에서 볼 수 있듯이 가장 큰 176b bloomz 모델은 비슷한 크기의 gpt-3 모델보다 성능이 뛰어나다.habana gaudi 가속기를 사용하여 100k lmentry 프롬프트에서 bloomz 모델(최대 176b 매개변수)로 생성된 언어 출력을 자동으로 평가또한, 허깅 페이스는 첨단 텍스트-이미지 생성을 위한 또 다른 생성 ai 모델이자 널리 사용되는 dall-e 이미지 생성기의 오픈 액세스 대안인 스테빌리티 ai(stability ai)의 스테이블 디퓨전(stable diffusion)이 인텔 어드밴스드 매트릭스 익스텐션(intel® amx)이 내장된 4세대 인텔 제온 스케일러블 프로세서에 코드 변경 없이 평균 3.8배 더 빠르게 실행된다고 발표했다.머신러닝을 위한 사용자 지정 형식인 bfloat16과 함께 파이토치 인텔 익스텐션을 사용하면 자동 혼합 정밀도가 2배 더 빨라지고 지연 시간이 5초로 줄어들어 초기 기준선인 32초보다 거의 6.5배 더 빨라진다. 허깅 페이스 웹사이트에서 인텔 cpu(4세대 제온 프로세서)에서 실행되는 실험적인 안정적 확산 데모에서 직접 프롬프트를 사용해 볼 수 있다.에마드 모스타크(emad mostaque) 스테빌리티 ai 설립자 겸 최고경영자(ceo)는 스테빌리티에서는 모든 사람이 스스로 ai 기술을 구축할 수 있도록 지원하고자 한다며 인텔은 4세대 사파이어 래피즈 cpu부터 가우디와 같은 가속기에 이르기까지 이기종 제품에서 스테이블 확산 모델을 효율적으로 실행할 수 있도록 지원했으며, 따라서 ai의 대중화를 위한 훌륭한 파트너라고 생각한다. 차세대 언어, 비디오 및 코드 모델과 그 이후에도 협력할 수 있기를 기대한다고 말했다.오픈 비노(openvino)는 스테이블 디퓨전 추론을 더욱 가속화한다. 4세대 제온 cpu와 결합하면 3세대 인텔 제온 스케일러블 cpu에 비해 약 2.7배의 속도가 향상된다. 인텔 아키텍처에서 엔드투엔드 파이프라인을 가속화하기 위해 오픈 비노가 지원하는 도구인 옵티멈 인텔(optimum intel)은 평균 지연 시간을 추가 3.5배, 전체 약 10배까지 줄일 수 있다.(참고: 아래는 '인텔과 허깅페이스는 함께 생성형 ai 컴퓨팅 챌린지에 도전' 발표 영상으로 카비타 프라사드(kavitha prasad) 인텔 부사장 겸 데이터센터, ai, 클라우드 실행 및 전략 총괄과 라마 나흐만 인텔 펠로우 겸 예측컴퓨팅연구소 디렉터, 제프 부디어 허깅 페이스 제품 디렉터, 다니엘 뉴먼 업계 분석가와 함께 생성형 ai가 전 세계 컴퓨팅 수요에 미치는 영향, 개방형 생태계가 중요한 이유, 최신 ai 개발에서 윤리의 역할에 대해 어떻게 생각해야 하는지에 대해 토론하고 있다.)<챕터: 챗gpt란 무엇인가– 1:14, 생성형 ai컴퓨팅 챌런지 해결 방안– 3:58, 개방형 생태계의 중요성– 6:42, 대규모 모델의 컴퓨팅 수요 증가 주도– 8:51, ai의 윤리적 의미– 15:38, 허깅 페이스로 ai민주화– 20:18, 개방형 생태계를 통한 ai 투명성– 27:36, 한 번 개발로 어디서든 배포– 30:40>가격, 성능 및 효율성 문제 해결더불어, 더 나은 성능에 대한 요구를 충족하면서 전력 사용량을 줄여야 하는 중요한 과제를 해결하기 위해서는 보다 지속 가능한 솔루션을 쉽게 이용할 수 있어야 한다. 개방형 생태계는 발전을 제한하는 장애물을 제거해 개발자 작업에 가장 적합한 하드웨어 및 소프트웨어 도구로 혁신할 수 있도록 지원한다.1세대 가우디와 동일한 고효율 아키텍처를 기반으로 구축되어 가우디2는 aws 클라우드의 동급 엔비디아 기반 인스턴스보다 최대 40% 더 나은 가격 대비 성능을 제공하며 대규모 워크로드에 새로운 차원의 성능과 효율성을 제공한다.또한 ai 워크로드를 실행할 때 전력 효율성도 입증했다. 슈퍼마이크로 가우디2 서버와 슈퍼마이크로 엔비디아 a100 서버 간의 전력 소비량 평가에서 가우디2는 인기 있는 컴퓨터 비전 워크로드를 실행할 때 a100 서버보다 와트당 처리량에서 1.8배의 우위를 보였다.1대규모 ai 워크로드에는 전력 효율성을 높여주는 유연한 개방형 솔루션과 함께 한번 구축된 모델을 어디서나 배포할 수 있는 접근 방식을 필요로 한다. 4세대 제온 프로세서는 인텔에서 가장 지속 가능한 데이터센터 프로세서로, 에너지 효율성과 전력 절감을 향상시킨다.인텔 amx와 같은 내장형 가속기를 사용하면 광범위한 ai 워크로드 및 사용 사례에서 추론 및 학습 성능을 10배 향상3시킬 수 있으며, 인텔의 이전 세대 대비 와트당 성능을 최대 14배까지 향상시킬 수 있다.윤리적 ai의 미래 지원생성형 ai는 인간의 능력을 지원하고 증폭하는 강력한 도구이지만, 이러한 시스템의 개발과 배포는 인간 중심의 접근 방식에서 비롯됐다. 시스템이 윤리적 문제없이 잠재력을 최대한 발휘하려면 책임감 있는 ai 거버넌스가 필요하다. ai의 윤리를 보호하는 가장 좋은 방법은 학습 및 데이터 세트 전반에서 투명성을 촉진하는 개방형 생태계를 이용하는 것이다.투명한 ai 공급망은 ai가 책임감 있게 개발되도록 보장하고 공급망의 윤리적 부채를 줄여준다. 이러한 투명성을 통해 개발자는 데이터 세트와 모델의 적합성을 평가하고, 결과를 복제하고, 사용 컨텍스트에 대한 윤리적 우려 사항을 파악할 수 있다.생성 ai는 더 큰 ai 모자이크의 한 조각이다. ai의 대중화를 위한 인텔의 접근 방식은 하드웨어의 고유한 강점, 개방형 에코시스템 지원, 미래를 위한 적절한 투자를 결합하여 생성형 ai를 포함한 모든 형태의 ai에 대한 컴퓨팅 요구를 충족하고 있다.모든 사람들이 손쉽게 컴퓨팅 및 도구를 사용할 수 있도록 지원하기 위한 인텔의 접근 방식은 대규모 언어 모델 구축에 대한 접근을 가능하게 하여 비용을 절감하고 형평성을 개선한다. 예를 들어, 인텔은 루게릭병 환자들이 보다 효과적으로 의사소통할 수 있도록 llm을 맞춤화하는 데 주력하고 있다.개발자 커뮤니티에서 해당 모델을 각자의 용도에 맞게 조정할 수 있도록 지원하면 도움이 필요한 사람들이 손쉽게 접근할 수 있다.ai는 먼 길을 걸어왔지만 앞으로 훨씬 더 전진할 필요가 있다. 인텔은 신뢰를 바탕으로, 선택권을 제공하며, 업계 전반의 상호 운용성을 보장하기 위해 개방형 생태계를 지속적으로 개발하고 있다. 또한 다학제적 접근 방식을 사용하여 에너지 효율적인 솔루션을 제공하고 인간-ai 협업을 통해 ai로 인간의 잠재력을 증폭하는데 주력하고 있다. 개방적인 접근 방식이 최선의 길이다.",
        "summary": "   개발자는 생성 AI를 포함한 모든 형태의 AI가 잠재력을 최대한 발휘할 수 있도록 유연하고 개방적이며 에너지 효율적이고 지속 가능한 솔루션으로 한 번 구축해 어디나 배포할 수 있어야 한다.인텔의 AI 하드웨어 가속기와 4세대 인텔 제온 스케일러블 프로세서에 내장된 가속기는 성능 및 와트당 성능 향상을 제공하여 생성 AI의 성능, 가격 및 지속 가능성 요구 사항을 충족시킨다.사람이 만든 콘텐츠를 모방할 수 있는 생성 AI는 일상 생활의 여러 측면을 변화시킬 수 있는 놀라운 기회를 제공한다.다만, 인간처럼 대화할 수 있는 생성형 AI 챗봇인 챗GPT에 대한 관심이 증폭되면서, 기존 데이터 센터 아키텍처의 장애물에 대해 주목하게 됐다.개발자 커뮤니티에서 해당 모델을 각자의 용도에 맞게 조정할 수 있도록 지원하면 도움이 필요한 사람들이 손쉽게 접근할 수 있다.",
        "gentime": "2023-04-04T02:52:49.000Z",
        "img": "https://cdn.aitimes.kr/news/thumbnail/202304/27703_41742_513_v150.jpg",
        "link": "https://www.aitimes.kr/news/articleView.html?idxno=27703",
        "companytag": {
            "#디오": 1
        },
        "imagelist": "n",
        "keywords": [
            "지속가능성",
            "허깅페이스가",
            "인텔과",
            "해결",
            "및",
            "생성",
            "위한",
            "여정",
            "ai",
            "인텔",
            "리뷰",
            "수",
            "컴퓨팅과",
            "함께하는",
            "있도록",
            "있는",
            "인텔의",
            "더",
            "개방형"
        ],
        "GPT4": 0,
        "트랜스포머": 1,
        "사용량": 1,
        "GPT4_트랜스포머_사용량": 2,
        "차트이미지경로": "",
        "tvcharturl": ""
    },
    {
        "title": "국내 최고 자본시장Capital Markets 미디어. ",
        "newstext": "   이 기사는 2023년 03월 06일 07:45 thebell 에 표출된 기사입니다.mwc 2023에 참여한 sk텔레콤과 kt가 유무선 통신 서비스를 고도화해 힘을 싣는 신사업 분야의 경쟁력을 보여줬다. 전시 아이템을 살펴보면 차세대 통신을 제외하고도 일부 콘텐츠가 겹쳤다. 특히 ai 반도체와 메타버스 등 새로운 먹거리를 놓고 격전을 예고했다.sk텔레콤은 지난해 분사한 사피온을 중심으로, kt는 지분을 투자한 리벨리온과 함께 ai 반도체 설계 시장에 뛰어들었다. 양사 초거대 ai와 접목해 시너지를 극대화할 방침이다. 메타버스 부문에서는 sk텔레콤의 글로벌 확장 전략이 돋보인다. kt는 b2b에 이어 b2c 신규 메타버스 서비스를 선보일 채비를 마쳤다.'ai 컴퍼니'를 지향하는 sk텔레콤은 mwc 2023 행사장에 부스를 마련하고 ai processor 부문에 사피온x220을 전시했다. ai 서비스를 구현하려면 대규모 연산을 초고속·저전력으로 실행하는 프로세서가 필요하다. 이런 효율성을 특화한 비메모리 반도체가 ai 반도체다.앞서 내부적으로 룬샷 태스크포스(loonshot tf)를 꾸려 자체 ai 액셀러레이터를 개발해 온 sk텔레콤은 2020년 '사피온 x220'을 만들었다. gpu(그래픽처리장치)와 비교해 딥러닝 연산속도는 1.5배 빠른데 전력 사용량은 80%에 불과하고 가격도 절반 수준이다. 경쟁력을 제고하고자 2021년 말 해당 연구개발(r&d) 조직을 별도로 분사했다.사피온은 sk텔레콤과 공동의 태스크포스(tf) 조직을 만들어서 ai 반도체를 sk텔레콤 서비스에 마이그레이션하는 작업을 진행하고 있다. ai 기술을 통해 오래된 영상이나 음원의 화질을 고화질로 개선하는 sk텔레콤의 솔루션 '슈퍼노바'에도 적용됐다.올 하반기에는 차기작인 'x330'을 출시할 예정이다. 전작과 비교해 4배 수준의 성능을 예고했다.사피온 부스 관계자는 npu(신경망처리장치)는 gpu에 비해 새로운 수요에 대응하는 데는 시간은 많이 걸리지만 저렴한 가격으로 특화 서비스에서는 더 나은 성능을 보여준다며 전력 소모량도 gpu와 비교해 4배가량 적어 가성비 측면에서 훌륭하다고 볼 수 있다고 설명했다.사피온은 대외적으로도 가치를 인정받았다. 작년 초에는 sk스퀘어, sk하이닉스, sk텔레콤으로 구성된 'sk ict 연합'을 구축했고 이들이 총 800억원을 투입해 출범했다. 최근에는 국내외 투자자를 유치하는 데 성공해 1년도 채 되지 않은 시점에 기업가치를 6배 이상 인정받았다. 구체적인 내용은 조만간 발표할 예정이다.'디지코(digico)' kt 역시 초거대 ai '믿음' 상용화에 나서면서 ai 반도체 풀스택(full-stack) 인프라를 구축하고 있다. 그 일환으로 지난해 ai 반도체를 설계하는 리벨리온에 300억원, ai 인프라 서비스를 담당하는 모레(moreh) 등에 전략 투자를 진행했다.리벨리온 역시 kt 부스 안에 데이터센터용 5나노 ai 반도체 '아톰'을 전시했다. 챗gpt의 원천기술인 트랜스포머 모델을 지원하는 국내 최초의 ai 반도체다. 기존 국내 npu들은 비전모델만 가속할 수 있었지만 아톰은 언어모델까지 가속이 가능하다. 아톰은 모레의 인프라 솔루션과 결합해 kt 데이터센터에 탑재된다.북미에 수조원 규모의 npu 회사들이 있지만 아직 유의미한 npu-데이터센터 레퍼런스가 없는 상황이다. 이에 세 회사는 협업의 성과물인 ai 풀스택을 가지고 데이터센터를 보유한 동남아 지역 통신사업자를 공략한다는 그림을 그리고 있다.오는 4월 초 공신력 있는 ai칩 벤치마크 테스트인 엠엘퍼프(mlperf) 결과를 통해 세계적인 성능을 보여주겠다는 포부를 안고 있다. 4월 말에는 믿음의 경량화 모델을 아톰칩에서 구동할 예정이다. 아울러 kt클라우드 고객도 올 상반기 중으로 아톰칩을 사용할 수 있을 전망이다.메타버스 역시 sk텔레콤과 kt가 공통으로 전시한 콘텐츠에 해당한다. '이프랜드(ifland)'는 지난 mwc 2022 행사에서 sk텔레콤의 전시 핵심 아이템이기도 했다.이번에는 작년 9월 선보인 아바타 코스튬을 쉽고 빠르게 제작할 수 있는 '이프랜드 스튜디오(ifland studio)'를 선보였다. 향후 이 코스튬을 사고파는 마켓플레이스도 구축하고 '이프랜드 포인트'를 통해 거래할 수 있도록 할 예정이다.아울러 이프랜드는 지난해 11월 북미, 유럽, 중동, 아시아 등 49개국에 동시 출시됐다. mwc 2023을 기점으로 글로벌 진출에 박차를 가하는 모양새다. 우선 도이치텔레콤(deutsche telekom), 티모바일us(t-mobile us)와 각각 이프랜드의 독일·미국 진출에 대해 합의했다.아세안(asean) 및 남아시아 11개 국가에서 약 2억명의 가입자를 보유한 악시아타(axiata)의 전체 자회사를 대상으로 이프랜드 서비스를 확장하기로 했다. 메타버스 플랫폼 관련 비즈니스 창출 및 상호 경쟁력 강화를 위한 ai 기반 사업 기회 협력 등에 대해서도 합의했다.또 말레이시아 1위 사업자인 셀콤디지와(celcomdigi)와는 현지 이프랜드 이용자 규모 증대 및 신규 사업 기회 모색을 위한 업무협약을 체결했다.후발주자인 kt는 b2c와 b2b·b2g로 플랫폼을 달리 선보이게 됐다. 작년 12월 선보인 b2b 메타버스 솔루션 '메타라운지'는 고객사에 맞춰 커스터마이징이 가능한 게 특징이다.가령 교육기관에서 스마트캠퍼스가 필요하면 실제 모양을 본따 만들 수 있다. ai 홈트인을 특징으로 삼아 사용자가 사는 아파트 주소를 입력하면 메타버스 세상에 이를 구현하고 입맛에 맞게 꾸밀 수 있다. 챗gpt처럼 kt의 초거대 ai 믿음을 활용한 ai npc도 구상 중이다. 메타버스 내 집 밖 '지니타운'에는 오락실, 카페 등을 배치하고 친구들을 초대할 수 있게끔 한다.지니버스는 이달 중 베타서비스를 거쳐 이르면 다음달 정식 출시할 전망이다. kt그룹 내 ena 미디어 콘텐츠를 체험하는 방안도 고려하고 있다. 아직 확정된 바는 없지만 일본 통신사로 오랜 기간 kt와 인연을 맺어온 ntt도코모와도 아파트 도면 데이터베이스(db)를 구축하는 등 글로벌 진출을 논의하는 것으로 알려졌다.",
        "summary": "   특히 AI 반도체와 메타버스 등 새로운 먹거리를 놓고 격전을 예고했다.SK텔레콤은 지난해 분사한 사피온을 중심으로, KT는 지분을 투자한 리벨리온과 함께 AI 반도체 설계 시장에 뛰어들었다.KT는 B2B에 이어 B2C 신규 메타버스 서비스를 선보일 채비를 마쳤다.AI 서비스를 구현하려면 대규모 연산을 초고속·저전력으로 실행하는 프로세서가 필요하다.'디지코(DIGICO)' KT 역시 초거대 AI '믿음' 상용화에 나서면서 AI 반도체 풀스택(Full-Stack) 인프라를 구축하고 있다.챗GPT처럼 KT의 초거대 AI 믿음을 활용한 AI NPC도 구상 중이다.",
        "gentime": "none",
        "img": "https://image.thebell.co.kr/news/photo/2023/03/01/20230301194721656_n.jpg",
        "link": "https://www.thebell.co.kr/free/content/ArticleView.asp?key=202302261336381520107533",
        "companytag": {
            "#디오": 1,
            "#나노": 1
        },
        "imagelist": "n",
        "keywords": [
            "자본시장capital",
            "초거대",
            "이프랜드",
            "있다",
            "메타버스",
            "markets",
            "국내",
            "통해",
            "수",
            "등",
            "서비스를",
            "지난해",
            "최고",
            "미디어",
            "ai"
        ],
        "GPT4": 0,
        "트랜스포머": 1,
        "사용량": 1,
        "GPT4_트랜스포머_사용량": 2,
        "차트이미지경로": "",
        "tvcharturl": ""
    },
    {
        "title": "기획 기업 생사 가르는 AI발 경영혁신. ",
        "newstext": "   경영·생산 보조도구넘어 전면에자율차·로봇·반도체 공격적 전개제조·통신·금융 등 전방위 확산카카오브레인-바이브컴퍼니, 포춘 코리아 2월호 표지 제작카카오브레인 제공 저작권자 디지털타임스, 무단 전재 및 재배포 금지 국내 대표 기업들이 ai(인공지능)발 골드러시에 뛰어들고 있다. ai를 어떻게 활용하느냐가 기업의 흥망성쇠를 가르고 업계 내 순위를 바꿀 전망이기 때문이다. 특히 ai를 경영과 생산성 향상의 보조도구로 쓰는 데서 그치지 않고 통신, 금융 등 상품설계에 활용하는 한편 자율주행차, 로봇, ai반도체 등 신사업을 공격적으로 전개하고 있다.31일 업계에 따르면 lg그룹 산하 lg ai연구원은 자체 개발한 초거대 ai '엑사원'에 이미지를 텍스트화하는 기술인 '이미지 캡셔닝' 능력을 강화하기 위해 전 세계 연구자들을 대상으로 한 대회를 오는 4월까지 개최한다.ai가 처음 본 사물이나 동물, 풍경 등 다양한 이미지를 스스로 이해하고 유추한 결과를 글로 표현하는 것이 핵심이다. 의학용은 물론 자율주행 등 다양한 사업에 적용 가능하다.lg그룹은 이미 엑사원을 다양한 사업영역에 활용하고 있다. lg전자는 주 단위로 지역별 제품 판매 수요를 예측하는 데 ai를 활용한다. lg이노텍은 카메라 렌즈와 센서의 중심을 맞추는 공정에 ai 기술을 도입해 최적화 기간을 50% 이상 단축했다.삼성전자는 비스포크 가전제품에 ai를 접목해 에너지 효율성을 높이고 있다. 소비자가 가전제품의 누진세 구간이나 월별 전력 목표량을 설정하고 ai 절약 모드를 실행하면 에너지 사용량을 20%까지 줄일 수 있다. 무풍에어콘, 식기세척기, 홈카메라, 스마트 전구·버튼 등에도 ai를 적용했다. 반도체부터 가전제품, 스마트폰에 이르는 제품의 글로벌 공급경로를 최적화하는 데도 ai를 활용한다. 네이버와는 초거대 ai에 필요한 전용 ai반도체와 솔루션을 개발하고 있다.sk는 통신, 반도체, uam(도심항공교통) 등 기존 사업과 신사업 전반에 ai를 활용한다. sk텔레콤은 gpt-3 기반 ai 비서 '에이닷'에 오픈ai가 개발한 챗gpt 접목을 추진하는 등 최근 뜨거운 챗gpt 이슈에 가세했다.kt도 상반기 중 2000억개 파라미터를 보유한 초거대ai '믿음' 기반의 대화형 서비스를 공개할 예정이다. 믿음은 감성을 이해하고 인간과 공감하는 ai가 목표다. lg유플러스는 lg그룹의 초거대 ai '엑사원'과 연계한 서비스를 연구하고 있다.현대자동차는 자율주행과 로봇에 ai를 접목하고 있다. 미국에 로봇ai연구소를 설립해 로보틱스, 자율주행, ai 연구와 사업화에 나서는 한편 인수한 자율주행 스타트업 포티투닷을 통해 ai와 소프트웨어 기술 확보에 집중한다. 자동차 공장의 순찰도 보스턴다이내믹스의 4족 보행로봇 '스팟'에 맡기고 있다.은행들도 ai를 대면·비대면 전반에 활용한다. kb국민은행은 최근 ai 챗봇 서비스의 월간 활성화 이용자(mau)가 100만명을 돌파했다고 밝혔다. 국민은행은 지난 1월 ai 기반 '콜봇 서비스'를 수신상품 만기 안내에 처음 도입했다. 우리은행도 ai 기술을 활용한 'ai상담봇' 서비스를 시작했다. 하나은행은 모바일 앱에 'ai 뱅커(은행원)'를 도입했다.증권업계는 버추얼휴먼을 활용한다. 한국투자증권도 버추얼휴먼 '한지아'를 주인공으로 한 유튜브 콘텐츠를 만들었다.국내 양대 플랫폼 기업인 네이버와 카카오는 'ai 네이티브 기업'으로 변신 중이다. 네이버는 자체 개발한 초거대 ai '하이퍼클로바'를 검색, 쇼핑, 예약 등 전 분야에 활용한다. 한국어에 특화된 하이퍼클로바를 앞세워 ai 패권 경쟁에서 주도권을 확보하겠다는 구상이다.카카오는 ai 연구개발 자회사 카카오브레인 주도로 사업을 전개한다",
        "summary": "",
        "gentime": "none",
        "img": "http://contents.dt.co.kr/images/202302/2023020102100151029001[1].jpg?var=4603",
        "link": "http://www.dt.co.kr/contents.html?article_no=2023020102100151029001&ref=naver",
        "companytag": {
            "#카카오": 5,
            "#삼성전자": 1,
            "#바이브컴퍼니": 1,
            "#전방": 1
        },
        "imagelist": "n",
        "keywords": [
            "경영혁신",
            "가르는",
            "초거대",
            "있다",
            "자율주행",
            "다양한",
            "등",
            "활용한다",
            "자체",
            "ai발",
            "ai를",
            "기업",
            "기획",
            "서비스를",
            "생사",
            "ai"
        ],
        "GPT4": 0,
        "트랜스포머": 0,
        "사용량": 1,
        "GPT4_트랜스포머_사용량": 1,
        "차트이미지경로": "",
        "tvcharturl": ""
    }
]